{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f1c836",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b9db6f",
   "metadata": {},
   "source": [
    "- Task 1:- To prepare a complete data analysis report on the given data.\n",
    "\n",
    "\n",
    "- Task 2:-\n",
    "\n",
    "  a) To create a robust machine learning algorithm to accurately predict the price of the house given the various factors across the market.      \n",
    "\n",
    "  b) To determine the relationship between the house features and how the price varies based on this.\n",
    "\n",
    "\n",
    "- Task3:- \n",
    "     \n",
    "     To come up with suggestions for the customer to buy the house according to the area, price and other requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4a59a",
   "metadata": {},
   "source": [
    "# Imporitng libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc02a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43fd5a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93e481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3816ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ef955",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1973dc",
   "metadata": {},
   "source": [
    "# Domain Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33a428",
   "metadata": {},
   "source": [
    "- Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this  dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "  With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992fd3c",
   "metadata": {},
   "source": [
    "MSSubClass:\n",
    "    Represents the type of dwelling involved in the sale, such as 1-STORY 1946 & NEWER ALL STYLES, capturing the style \n",
    "    and age of the property.\n",
    "\n",
    "MSZoning: \n",
    "    Identifies the general zoning classification of the sale, offering insights into the permissible land use, such\n",
    "    as residential low density or medium density.\n",
    "\n",
    "LotFrontage: \n",
    "    Indicates the linear feet of street connected to the property, giving a measure of the property's frontage and\n",
    "    its potential impact on accessibility and aesthetics.\n",
    "\n",
    "LotArea: \n",
    "    Reflects the lot size in square feet, a crucial factor influencing the overall property value.\n",
    "\n",
    "Street: \n",
    "    Specifies the type of road access to the property, distinguishing between paved and gravel roads, affecting\n",
    "    convenience and property value.\n",
    "\n",
    "Alley: \n",
    "    Describes the type of alley access to the property, providing information on additional access points.\n",
    "\n",
    "LotShape: \n",
    "    Defines the general shape of the property's lot, influencing property aesthetics and potentially affecting land utility.\n",
    "\n",
    "LandContour: \n",
    "    Indicates the flatness of the property, impacting construction feasibility and landscaping possibilities.\n",
    "\n",
    "Utilities: \n",
    "    Specifies the type of utilities available, such as all public utilities or electricity only, affecting convenience\n",
    "    and livability.\n",
    "\n",
    "LotConfig: \n",
    "    Describes the lot configuration, providing insights into how the property is situated within its surroundings.\n",
    "\n",
    "LandSlope: \n",
    "    Identifies the slope of the property, which can influence drainage, landscaping, and construction considerations.\n",
    "\n",
    "Neighborhood: \n",
    "    Represents physical locations within Ames city limits, capturing the neighborhood's influence on property values\n",
    "    and desirability.\n",
    "\n",
    "Condition1 and Condition2: \n",
    "    Indicate the proximity to various conditions (e.g., railroad, park), offering insights into potential nuisances\n",
    "    or amenities.\n",
    "\n",
    "BldgType: \n",
    "    Specifies the type of dwelling, distinguishing between single-family, townhouse inside unit, etc.\n",
    "\n",
    "HouseStyle: \n",
    "    Represents the style of dwelling, such as 1-story or 2-story, contributing to the property's architectural characteristics.\n",
    "\n",
    "OverallQual and OverallCond: \n",
    "    Convey the overall material and finish quality, as well as the overall condition, influencing the property's\n",
    "    appeal and value.\n",
    "\n",
    "YearBuilt and YearRemodAdd: \n",
    "    Provide the year the house was built and remodeled, helping assess the property's age and recent upgrades.\n",
    "\n",
    "RoofStyle and RoofMatl: \n",
    "    Describe the roof type and material, contributing to the property's aesthetics and durability.\n",
    "\n",
    "Exterior1st and Exterior2nd: \n",
    "    Indicate the exterior covering on the house, influencing curb appeal and maintenance requirements.\n",
    "\n",
    "MasVnrType and MasVnrArea: \n",
    "    Specify the masonry veneer type and area, adding to the property's visual appeal.\n",
    "\n",
    "ExterQual and ExterCond: \n",
    "    Capture the exterior material quality and condition, influencing the property's durability and maintenance needs.\n",
    "\n",
    "Foundation: \n",
    "    Represents the type of foundation, essential for assessing the property's structural integrity.\n",
    "\n",
    "BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF: \n",
    "    Provide insights into basement quality, condition, exposure, and size, crucial for assessing additional living space.\n",
    "\n",
    "Heating, HeatingQC: \n",
    "    Indicate the type of heating and heating quality, impacting comfort and energy efficiency.\n",
    "\n",
    "CentralAir: \n",
    "    Specifies whether the property has central air conditioning, contributing to comfort and property value.\n",
    "\n",
    "Electrical: \n",
    "    Represents the electrical system, a critical component for safety and functionality.\n",
    "\n",
    "1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea: \n",
    "    Provide square footage details for various living areas, influencing the property's size and layout.\n",
    "\n",
    "BsmtFullBath, BsmtHalfBath, FullBath, HalfBath: \n",
    "    Describe bathroom features, contributing to the property's functionality.\n",
    "\n",
    "BedroomAbvGr, KitchenAbvGr, KitchenQual: \n",
    "    Specify the number of bedrooms and kitchens, along with kitchen quality, influencing livability and property value.\n",
    "\n",
    "TotRmsAbvGrd: \n",
    "    Indicates the total rooms above ground, offering insights into the property's spatial layout.\n",
    "\n",
    "Functional: \n",
    "    Represents the home's functionality rating, crucial for assessing usability and appeal.\n",
    "\n",
    "Fireplaces, FireplaceQu: \n",
    "    Convey the number of fireplaces and fireplace quality, contributing to ambiance and property value.\n",
    "\n",
    "GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond: \n",
    "    Provide details on the garage, including type, year built, and size, influencing property utility and value.\n",
    "\n",
    "PavedDrive: \n",
    "    Specifies whether the property has a paved driveway, impacting convenience and aesthetics.\n",
    "\n",
    "WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch: \n",
    "    Capture porch and deck features, enhancing outdoor living and visual appeal.\n",
    "\n",
    "PoolArea, PoolQC: \n",
    "    Indicate pool area and quality, contributing to luxury and property value.\n",
    "\n",
    "Fence: \n",
    "    Describes fence quality, offering privacy and influencing property aesthetics.\n",
    "\n",
    "MiscFeature, MiscVal: \n",
    "    Specify miscellaneous features and their values, potentially adding unique elements to the property.\n",
    "\n",
    "MoSold, YrSold: \n",
    "    Represent the month and year of sale, capturing the temporal aspect of property transactions.\n",
    "\n",
    "SaleType, SaleCondition: \n",
    "    Describe the type and condition of the sale, providing insights into the transaction dynamics.\n",
    "\n",
    "SalePrice: \n",
    "    The target variable, representing the sale price of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d6bd2",
   "metadata": {},
   "source": [
    "# Basic checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call the dataframe and do basic checks\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72382c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec032ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LotFrontage'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['MiscFeature'].isnull()==True]\n",
    "data['MiscFeature'].isnull().sum()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum of features\n",
    "pd.set_option('display.max_rows',None)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ceca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print() al the unique value of target value\n",
    "data.SalePrice.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here in target we have no null value\n",
    "data.SalePrice.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row',None)\n",
    "data.SalePrice.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5037be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3490317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include = 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61744a58",
   "metadata": {},
   "source": [
    "### Fetching only categorical columns from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def92967",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = data.select_dtypes('object').columns\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b0d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating a sub_data for categorcal variables and sales price\n",
    "\n",
    "data_categorical = pd.concat([data[categorical_cols],data['SalePrice']], axis=1)\n",
    "data_categorical.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categorical.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f00e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print() all the categorical column with its unique values\n",
    "categorical_col = []\n",
    "\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == object and len(data[column].unique()) <= 50:\n",
    "        categorical_col.append(column)\n",
    "        print(f\"{column}: {data[column].unique()}\")\n",
    "        print(\"=================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d637fb88",
   "metadata": {},
   "source": [
    "##### Numerical data statistical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c9c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68395df5",
   "metadata": {},
   "source": [
    "##### Insights from numercial data statistical measures:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b725bd",
   "metadata": {},
   "source": [
    "1)->General Information:\n",
    "\n",
    "The dataset contains information on housing with 1460 entries.\n",
    "The target variable is SalePrice.\n",
    "\n",
    "\n",
    "2)->Summary Statistics:\n",
    "\n",
    "SalePrice has a mean of approximately $180,921 and a median (50th percentile) of $163,000. The prices vary widely, ranging from $34,900 to $755,000.\n",
    "\n",
    "\n",
    "3)->Year Information:\n",
    "\n",
    "The houses in the dataset were generally built between 1872 and 2010, with an average year of construction around 1971.\n",
    "The average year of remodeling is approximately 1984, with a range from 1950 to 2010.\n",
    "\n",
    "\n",
    "\n",
    "4)->Lot Characteristics:\n",
    "\n",
    "    \n",
    "LotFrontage has missing values (1201 non-null), and the mean lot frontage is approximately 70.\n",
    "LotArea varies widely, with an average lot area of approximately 10,516 square feet.\n",
    "\n",
    "\n",
    "5)->Quality and Condition:\n",
    "\n",
    "OverallQual and OverallCond represent the overall material and finish quality and overall condition of the house, respectively.\n",
    "OverallQual has a mean of approximately 6, indicating an above-average quality on average.\n",
    "\n",
    "\n",
    "6)->Living Area:\n",
    "\n",
    "The average above-ground living area (GrLivArea) is approximately 1,515 square feet.\n",
    "There is variation in low-quality finished square feet (LowQualFinSF), with an average of 5.84.\n",
    "\n",
    "\n",
    "7)->Basement Information:\n",
    "\n",
    "TotalBsmtSF represents the total square feet of the basement area, with an average of approximately 1,057 square feet.\n",
    "BsmtFullBath and BsmtHalfBath indicate the number of basement full bathrooms and half bathrooms, respectively.\n",
    "\n",
    "\n",
    "8)->Garage Information:\n",
    "\n",
    "GarageYrBlt has missing values (1379 non-null) and represents the year the garage was built.\n",
    "GarageCars and GarageArea represent the capacity and size of the garage, respectively.\n",
    "\n",
    "\n",
    "9)->Outdoor Features:\n",
    "\n",
    "WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, and ScreenPorch represent different types of porches and decks.\n",
    "There is variability in the presence of pools (PoolArea) and miscellaneous features (MiscVal).\n",
    "\n",
    "\n",
    "10)Time Information:\n",
    "\n",
    "Houses were sold between 2006 and 2010, with an average sale year of approximately 2008.\n",
    "MoSold represents the month of sale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb70398",
   "metadata": {},
   "source": [
    "###### Categorical data statistical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ad5dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe(include = 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ce932",
   "metadata": {},
   "source": [
    "##### Categorical data insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69661a3",
   "metadata": {},
   "source": [
    "A)->Cardinality:\n",
    "\n",
    "1)->The MSZoning feature has 5 unique values, with \"RL\" being the most frequent (1151 occurrences).\n",
    "\n",
    "2)->Street is binary with \"Pave\" occurring 1454 times.\n",
    "\n",
    "3)->Alley has two values (\"Grvl\" and \"Pave\"), with \"Grvl\" appearing 50 times.\n",
    "\n",
    "\n",
    "\n",
    "B)->Lot Characteristics:\n",
    "\n",
    "1)->LotShape has 4 unique values, with \"Reg\" being the most frequent (925 occurrences).\n",
    "\n",
    "2)->LandContour has 4 unique values, with \"Lvl\" being the most frequent (1311 occurrences).\n",
    "\n",
    "3)->Utilities is mostly constant, with \"AllPub\" occurring 1459 times.\n",
    "\n",
    "\n",
    "c)->Location and Configuration:\n",
    "\n",
    "1)->LotConfig has 5 unique values, with \"Inside\" being the most frequent (1052 occurrences).\n",
    "\n",
    "2)->LandSlope is mostly gentle (\"Gtl\") and appears 1382 times.\n",
    "\n",
    "\n",
    "D)->Neighborhood and Conditions:\n",
    "\n",
    "1)->Neighborhood has 25 unique values, with \"NAmes\" being the most frequent (225 occurrences).\n",
    "\n",
    "2)->Condition1 and Condition2 represent proximity to various conditions; most occurrences are \"Norm\" in both cases.\n",
    "\n",
    "\n",
    "E)->Building Characteristics:\n",
    "\n",
    "1)->BldgType mostly consists of single-family homes (\"1Fam\" - 1220 occurrences).\n",
    "\n",
    "2)->HouseStyle is predominantly one-story houses (\"1Story\" - 726 occurrences).\n",
    "\n",
    "3)->RoofStyle is mostly \"Gable\" (1141 occurrences), and RoofMatl is primarily \"CompShg\" (1434 occurrences).\n",
    "\n",
    "\n",
    "F)->Exterior and Masonry Veneer:\n",
    "\n",
    "1)->Exterior1st and Exterior2nd represent the exterior covering of the house; \"VinylSd\" is the most common for both.\n",
    "\n",
    "2)->MasVnrType has 5 unique values, with \"None\" being the most frequent (864 occurrences).\n",
    "\n",
    "\n",
    "G)->Basement Characteristics:\n",
    "\n",
    "1)->BsmtQual and BsmtCond represent the overall condition of the basement; both are mostly \"TA\" (Tabulated Area).\n",
    "\n",
    "2)->BsmtExposure is mostly \"No,\" indicating no exposure to a basement wall.\n",
    "\n",
    "\n",
    "H)->Heating and Air Conditioning:\n",
    "\n",
    "1)->Heating is mostly \"GasA,\" and HeatingQC is predominantly \"Ex\" (Excellent).\n",
    "\n",
    "2)->CentralAir is mostly \"Y,\" indicating central air conditioning.\n",
    "\n",
    "\n",
    "I)->Electrical and Kitchen Quality:\n",
    "\n",
    "1)->Electrical mostly consists of \"SBrkr.\"\n",
    "\n",
    "2)->KitchenQual is predominantly \"TA\" (Tabulated Area).\n",
    "\n",
    "\n",
    "J)->Fireplaces and Garage:\n",
    "\n",
    "1)->Functional is mostly \"Typ\" (Typical Functionality).\n",
    "\n",
    "2)->FireplaceQu represents the quality of fireplaces; \"Gd\" (Good) is most common.\n",
    "\n",
    "\n",
    "K)->Garage Characteristics:\n",
    "\n",
    "1)->GarageType mostly consists of attached garages (\"Attchd\" - 1365 occurrences).\n",
    "\n",
    "2)->GarageFinish is mostly \"Unf\" (Unfinished).\n",
    "\n",
    "\n",
    "L)->Paved Driveway and Pool:\n",
    "\n",
    "1)->PavedDrive is mostly \"Y,\" indicating a paved driveway.\n",
    "\n",
    "2)->PoolQC has only 3 non-null values and mostly \"Gd\" (Good).\n",
    "\n",
    "\n",
    "M)->Fence and Miscellaneous Features:\n",
    "\n",
    "1)->Fence has 157 occurrences of \"MnPrv\" (Minimum Privacy).\n",
    "\n",
    "2)->MiscFeature has 49 occurrences of \"Shed.\"\n",
    "\n",
    "\n",
    "N)->Sale Type and Condition:\n",
    "\n",
    "1)->SaleType mostly consists of \"WD\" (Warranty Deed - Conventional).\n",
    "\n",
    "2)->SaleCondition is mostly \"Normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6df7f",
   "metadata": {},
   "source": [
    "##### Continous features from dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ffe1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_numerical = data[numerical_cols]\n",
    "print(len(numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eed1c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_numerical.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd31d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical data along with its unique values\n",
    "numerical_column = []\n",
    "\n",
    "for column in data_numerical:\n",
    "    if data[column].dtypes == int and len(data[column].unique()) <= 50:\n",
    "        numerical_column.append(column)\n",
    "    print(f\"{column} :{data[column].unique()}\")\n",
    "    print('****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ec605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: check disctint values in each column\n",
    "data[numerical_cols].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c67091",
   "metadata": {},
   "source": [
    "### Relation date_time_year with target_variable:>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36197b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datetime_cols = [col for col in data if 'Yr'in  col or 'Year'in  col ]\n",
    "# datetime_cols\n",
    "datetime_col = data[['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold','SalePrice']]\n",
    "datetime_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in datetime_col.columns[:-1]:\n",
    "    plt.subplot(2,2,plotnumber)\n",
    "    plt.plot(datetime_col[column], datetime_col['SalePrice'], 'o', label = f\"{column} vs SalePrice\")\n",
    "    \n",
    "    plt.title(f\"{column} vs SalePrice\")\n",
    "    plt.xlabel(column, fontsize = 10)\n",
    "    plt.ylabel('SalePrice', fontsize = 10)\n",
    "    plotnumber += 1\n",
    "    plt.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_col.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5bdac",
   "metadata": {},
   "source": [
    "Positive Connection: \n",
    "    The strong positive correlation close to 1 between 'SalePrice' and 'YearBuilt', 'YearRemodAdd', and 'GarageYrBlt'\n",
    "    suggests that as these aspects related to the property's history and construction time increase, the home's selling\n",
    "    price tends to rise as well.\n",
    "\n",
    "Time and Sale Price: \n",
    "    The small negative correlation near 0 between 'SalePrice' and 'YrSold' hints at a subtle trend—when the sale year\n",
    "    increases, there's a slight tendency for the selling price to decrease, although this relationship is not very pronounced.\n",
    "\n",
    "Predictive Power: \n",
    "    The moderate to strong correlation values imply that 'YearBuilt', 'YearRemodAdd', and 'GarageYrBlt' could serve as\n",
    "    promising predictors for estimating 'SalePrice'. Essentially, changes in these features are associated with noticeable\n",
    "    changes in the property's selling price. However, keep in mind that correlation doesn't prove causation, and a \n",
    "    comprehensive analysis should consider various factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522488e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_discrete_cols = [col for col in numerical_cols if len(data[col].unique()) < 25 and col not in datetime_col]\n",
    "numerical_discrete_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_discrete = pd.concat([data[numerical_discrete_cols],data['SalePrice']], axis=1)\n",
    "data_discrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_continuous_cols = [col for col in numerical_cols if col not in numerical_discrete_cols and col not in datetime_col and col != 'Id']\n",
    "numerical_continuous_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4accdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_continous = data[numerical_continuous_cols]\n",
    "data_continous.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a1eb7",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e7deb",
   "metadata": {},
   "source": [
    "### Univarite Analysis and Bivariate Analysis-- Autoviz\n",
    "- Univarite Analysis:In univariate analysis, we focus on one thing at a time in our data, like a superhero investigating a single clue. We dig into its details, check for any weird stuff (outliers), and figure out what's typical about it (central tendencies). It's like zooming in on one character in a big story to understand their unique tale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1130c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import sweetviz as sv #  library for univariant analysis\n",
    "\n",
    "# my_report = sv.analyze(data)## pass the original dataframe\n",
    "\n",
    "# my_report.show_html() # Default arguments will generate to \"SWEETVIZ_REPORT.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53188d6",
   "metadata": {},
   "source": [
    "- Skewness:\n",
    "\n",
    "    Skewness is a measure of the asymmetry or lack of symmetry in a distribution. In simple terms, it indicates whether the data is skewed to the left or right. If the distribution is skewed to the right, it means that the tail on the right side is longer or fatter than the left side, and vice versa for left skewness. In a perfectly symmetrical distribution, the skewness is zero.\n",
    "    \n",
    "    \n",
    "what does positively and negatively skewness means?\n",
    "\n",
    "- Positive skewness:\n",
    "\n",
    "    If the data is positively skewed, it means that there are more data points on the left side of the distribution,\n",
    "    and the right tail is longer.\n",
    "    Positively skewed distributions are also called right-skewed distributions. This skewness pattern indicates that there are outliers or extreme values on the higher end of the data range, pulling the overall distribution in the positive direction. Understanding skewness is essential for accurately characterizing the shape of the data distribution, as it can impact the choice of statistical methods and the interpretation of results.The mean is typically greater than the median, as the larger values on the right side pull the mean in that direction.\n",
    "    \n",
    "    \n",
    "    \n",
    "- Negative Skewness:\n",
    "\n",
    "\n",
    "    If the data is negatively skewed, it means that there are more data points on the right side of the distribution,\n",
    "     and the left tail is longer.Negatively skewed distributions are also called left-skewed distributions. This skewness pattern indicates that there are outliers or extreme values on the lower end of the data range, pulling the overall distribution in the negative direction. Understanding skewness is crucial for accurately characterizing the shape of the data distribution, as it can influence the choice of statistical methods and the interpretation of results.The mean is typically less than the median, as the smaller values on the left side pull the mean in that direction.\n",
    "     \n",
    "     \n",
    "- IQR:\n",
    "\n",
    "\n",
    "     The Interquartile Range (IQR) is a measure of statistical dispersion, representing the range between the first quartile (25th percentile) and the third quartile (75th percentile) of a dataset. It is a useful tool in data analysis, providing insight into the spread of the middle 50% of the data, helping identify potential outliers and understand the central tendency more robustly.\n",
    "     \n",
    "     \n",
    "- Variance:\n",
    "\n",
    "     Variance is a statistical measure that quantifies the spread or dispersion of a set of data points. It calculates the    average squared difference between each data point and the mean of the dataset. A higher variance indicates greater variability among the values, while lower variance suggests that the values are closer to the mean, reflecting a more consistent dataset.\n",
    "     \n",
    "     \n",
    "- Standard Deviation:\n",
    "\n",
    "\n",
    "    Standard Deviation (std) is a statistical measure that quantifies the amount of variation or dispersion in a set of data points. It is the square root of the variance, providing a more interpretable metric in the same units as the original data. A higher standard deviation indicates greater variability among the values, while a lower standard deviation suggests that the values are closer to the mean, signifying less dispersion in the dataset.\n",
    "    \n",
    "    \n",
    "- Range:\n",
    "\n",
    "    Range is a simple measure of statistical dispersion, representing the difference between the maximum and minimum values in a dataset. It provides a quick assessment of the spread of data points. A wider range suggests greater variability among values, while a narrower range indicates less variability and a more concentrated dataset.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64164041",
   "metadata": {},
   "source": [
    "##### Insights from features using Sweetviz:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78fd5f",
   "metadata": {},
   "source": [
    "#### 1)-> MSSubClass:\n",
    "- Range:\n",
    "    Here range is 170 it implies a wide variation in the values of this variable.\n",
    "    The range represents the difference between the highest and lowest values. \n",
    "\n",
    "- Inter quantile range(IQR):\n",
    "    The Interquartile Range (IQR) of 50.0 in univariate analysis indicates that the middle\n",
    "    50% of the data is spread across a range of 50.0 units which is moderate neither large nor small.\n",
    "    A larger IQR suggests greater variability within the central portion of the dataset.\n",
    "\n",
    "- Standard Deviation:\n",
    "    A standard deviation of 42 indicates a relatively high degree of  spread\n",
    "    in the data points from the mean.\n",
    "    \n",
    "- Variance :\n",
    "    The value of 1789 for the variable (VAR) is the variance, which measures the average squared deviation\n",
    "    of each data point from the mean. In this context, it suggests a significant variability in the data.\n",
    "    \n",
    "- Kurtosis:\n",
    "    here we have kurtosis less than average which 3.\n",
    "    \n",
    "- Skewness:\n",
    "    Here the data is positively skewed.which means the data is not normal.\n",
    "    \n",
    "#### 2) ->LotFrontage:\n",
    "- Range: is 292\n",
    "- IQR: is 21\n",
    "- STD: is 24.3\n",
    "- VAR :is 590\n",
    "- Skewness:LotFrontage is positively skewed  \n",
    "#### 3) ->LotArea:\n",
    "- Range: is 214K\n",
    "- IQR :is 4048\n",
    "- STD: is 9981\n",
    "- VAR :99.6 M\n",
    "- Skewness:\n",
    "    Here the data is positively skewed\n",
    "#### 4)->YearBuilt: \n",
    "- Range is 138\n",
    "- IQR : is 46\n",
    "- STD is 30\n",
    "- VAR is 912\n",
    "- Skewness:\n",
    "    Here the distribution is negatively skewed\n",
    "#### 5)->YearRemodAdd:\n",
    "- Range is 60.0\n",
    "- IQR is 37\n",
    "- STD is 26\n",
    "- VAR is 426\n",
    "- Skewness:\n",
    "    Here the data is slightly in negatively skewed\n",
    "#### 6)->MasVnrArea:\n",
    "- Range: is 1600\n",
    "- IQR : is 166\n",
    "- STD: is 181\n",
    "- VAR : is 32785\n",
    "- Skewness:\n",
    "    Here data point is positively  skewed\n",
    "#### 7)->BsmtFinSF1:\n",
    "- Range is 5644\n",
    "- IQR is 712\n",
    "- STD is 456\n",
    "- Skewness:\n",
    "    Here the data is positively skewed\n",
    "#### 8)->BsmtFinSF2:\n",
    "- Range is 1474\n",
    "- IQR is 0.00\n",
    "- STD is 161\n",
    "- VAR is 26024\n",
    "- Skewness:\n",
    "    Here the data is positively skewed\n",
    "#### BsmtUnfSF:\n",
    "- Range is 2336\n",
    "- IQR is 585\n",
    "- STD is 442\n",
    "- VAR is 195K\n",
    "- Skewness:\n",
    "    Here the data is positively skewed\n",
    "#### 10)->TotalBsmtSF:\n",
    "- Range: is 6110\n",
    "- IQR: is 502\n",
    "- STD: is 439\n",
    "- VAR: is 192K\n",
    "- Skewness:\n",
    "    Here the data is Positively skewed\n",
    "#### 11)-> LowQualFinSF:\n",
    "- Range is 572\n",
    "- IQR is 0.00\n",
    "- STD is 48.6\n",
    "- VAR is 2364\n",
    "- Skewness: \n",
    "    Data is positively skewed\n",
    "    Here we have peakedness\n",
    "##### 12)->GrLivArea:\n",
    "- Range: is 5308\n",
    "- IQR is 647\n",
    "- STD is 525\n",
    "- VAR is 2364\n",
    "- Skewness:\n",
    "    Here data is positively skewed \n",
    "    Here we have peakedness\n",
    "##### 13)->TotRmsAbvGrd:\n",
    "- Range is 12.0\n",
    "- IQR is 2.00\n",
    "- STD is 1.63\n",
    "- VAR is 2.64\n",
    "- Skewness:\n",
    "    Here the data is Positively skewed\n",
    "    We have low kurtosis\n",
    "##### 14) ->GarageYrBlt:\n",
    "- Range is 110\n",
    "- IQR is  41\n",
    "- STD is 24.7\n",
    "- VAR is 610\n",
    "- Skewness: \n",
    "    Here the data is negativey skewed.Here we have low kurtosis\n",
    "#### 15)-GarageArea:\n",
    "- Range is 1418\n",
    "- IQR is 242\n",
    "- STD is 214\n",
    "- VAR is 45713\n",
    "- Skewness:\n",
    "    Here we have positive skewness\n",
    "    Here we have low kurtosis\n",
    "##### 16)->WoodDeckSF:\n",
    "- Range is 857\n",
    "- IQR is 168 \n",
    "- STD is 125\n",
    "- VAR is 15710\n",
    "- Skewness:\n",
    "    Here the data is positively skewed\n",
    "    Here we have no specific kurtosis\n",
    "#### 17)->OpenPorschSF:\n",
    "- Range is 547\n",
    "- IQR is 68.0\n",
    "- STD is 66.3\n",
    "- VAR is 4390\n",
    "- Skewness:\n",
    "    Here we have positively skewed data\n",
    "    We have peakedness in data \n",
    "#### 18)->EnclosedPorch:\n",
    "- Range is 553\n",
    "- IQR is 0.00\n",
    "- STD is 61.\n",
    "- VAR is 3736\n",
    "- Skewness: \n",
    "    Here we have Positively skewed data\n",
    "    We have high peakedness.\n",
    "##### 19)->3SsnPorch:\n",
    "- Range is 508\n",
    "- IQR is 0.00\n",
    "- STD is 29.3\n",
    "- VAR is 860\n",
    "- Skewness:\n",
    "    We have strong positively skewed data \n",
    "    We have extremely high peakedness.\n",
    "##### 20)->ScreenPorch:\n",
    "- Range is 480\n",
    "- IQR is 0.00\n",
    "- STD is 55.8\n",
    "- VAR is 3109\n",
    "- Skewness:\n",
    "    We have positive skewed data\n",
    "    Here we have high peakedness.\n",
    "##### 21)->PoolArea:\n",
    "- We have no clear insights here \n",
    "##### 22)->MoSold:\n",
    "- Range is 11.0\n",
    "- IQR is 3.00\n",
    "- STD is 2.70\n",
    "- VAR is 7.31\n",
    "- Skewness:\n",
    "    Here the data is positively skewd\n",
    "- We have extremely low kurtosis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2383279",
   "metadata": {},
   "source": [
    "### Histplot for univariate analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c3f47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data_continous[:-1]:\n",
    "    if plotnumber<=15 :     # as there are 15 columns in the data\n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.histplot(data_continous[column],  kde=True)\n",
    "        \n",
    "        plt.title(f'Histplot of {column}')\n",
    "        plt.xlabel(f\"{column} range\",fontsize=10)\n",
    "        plt.ylabel('Density', fontsize = 8)\n",
    "        plotnumber += 1\n",
    "    plt.xticks(rotation=90,fontsize=7)\n",
    "        #plt.xlabel(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370505b",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis for continous features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c250df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 25), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "for column in data_continous[:-1]:\n",
    "    if plotnumber <= 15:\n",
    "        plt.subplot(4,4,plotnumber)\n",
    "        sns.lineplot(x = data[column], y= data['SalePrice'], ci = None, label = f\"{column} vs SalePrice\")\n",
    "        \n",
    "        plt.title(f\"Line Plot for {column}\")\n",
    "        plt.xlabel(column, fontsize = 10)\n",
    "        plt.ylabel('SalePrice', fontsize = 10)\n",
    "        plotnumber += 1\n",
    "        plt.grid(True)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec61717",
   "metadata": {},
   "source": [
    "#### Scatterplot for bivariate analysis:\n",
    "          Here we will use scatterplot to see the outlier and behaviour of our data against target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1af0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 20), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "for column in data_continous[:-1]:\n",
    "    if plotnumber <= 15:\n",
    "        plt.subplot(4,4,plotnumber)\n",
    "        sns.scatterplot(x = data[column], y= data['SalePrice'],label = f\"{column} vs SalePrice\")\n",
    "        \n",
    "        plt.title(f\"scatter Plot for {column}\")\n",
    "        plt.xlabel(column, fontsize = 10)\n",
    "        plt.ylabel('SalePrice', fontsize = 10)\n",
    "        plotnumber += 1\n",
    "        plt.grid(True)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6d19b",
   "metadata": {},
   "source": [
    "#### Bivariate analysis of datetime column relation with SalePrice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in datetime_col.columns[:-1]:\n",
    "    plt.subplot(2,2,plotnumber)\n",
    "    sns.lineplot(x = data[column], y = data['SalePrice'],ci = None   ,label = f\"{column} vs SalePrice\")\n",
    "    \n",
    "    plt.title(f\"{column} vs SalePrice\")\n",
    "    plt.xlabel(column, fontsize = 10)\n",
    "    plt.ylabel('SalePrice', fontsize = 10)\n",
    "    plotnumber += 1\n",
    "    plt.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a10bc1",
   "metadata": {},
   "source": [
    "#### Univariate analysis of categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 30), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "for column in data_categorical.columns:\n",
    "    if plotnumber <= 43:\n",
    "        plt.subplot(11,4, plotnumber)\n",
    "        sns.countplot(x = data_categorical[column])\n",
    "        \n",
    "        plt.title(f'count of {column}')\n",
    "        plt.xlabel(column, fontsize = 10)\n",
    "        plt.ylabel('Accurance', fontsize = 10)\n",
    "        plotnumber += 1\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0a5a0",
   "metadata": {},
   "source": [
    "### Bivariate Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8c468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 30), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "for column in data_categorical.columns:\n",
    "    if plotnumber <= 43:\n",
    "        plt.subplot(11,4, plotnumber)\n",
    "        sns.barplot(x = data_categorical[column], y = data.SalePrice, ci = None)\n",
    "        \n",
    "        plt.title(f'Barplot of {column}')\n",
    "        plt.xlabel(column, fontsize = 10)\n",
    "        plt.ylabel('SalePrice', fontsize = 10)\n",
    "        plotnumber += 1\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61cab67",
   "metadata": {},
   "source": [
    "#### Bivariate analysis of discrete data against SalePrice :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 30), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "for column in data_discrete.columns[:-1]:\n",
    "    if plotnumber <= 43:\n",
    "        plt.subplot(11,4, plotnumber)\n",
    "        sns.barplot(x = data_discrete[column], y = data.SalePrice, ci = None)\n",
    "        \n",
    "        plt.title(f'Barplot of {column}')\n",
    "        plt.xlabel(column, fontsize = 10)\n",
    "        plt.ylabel('SalePrice', fontsize = 10)\n",
    "        plotnumber += 1\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed0548",
   "metadata": {},
   "source": [
    "### Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720029ed",
   "metadata": {},
   "source": [
    "1)-> MSZoning:\n",
    "    \n",
    "1)->'FV' (Floating Village Residential) tend to have higher SalePrice\n",
    "\n",
    "2)->'RL' zoning, or \"Residential Low Density,\" is the second-best, suggesting a positive impact on sale prices.\n",
    "\n",
    "3)-> properties with 'RM' and 'RH' zoning classifications, likely \"Residential Medium Density\" and \"Residential High Density,\" have similar effects on sale prices. Conversely, 'C (all)' zoning, representing commercial properties, has the least impact on sales prices.\n",
    "\n",
    "\n",
    "\n",
    "2)->Street:\n",
    "'Pave' (paved) road, they tend to have a higher impact on SalesPrice, and 'Grvl' (gravel) road access is the second most influential factor\n",
    "\n",
    "\n",
    "\n",
    "3)->Alley:\n",
    "Properties with a 'Pave' (paved) alley have a strong positive relationship with SalePrice, indicating higher sale prices. Additionally, properties with a 'Grvl' (gravel) alley show the second-highest association with the target variable, though likely with a slightly lower impact on sale prices compared to 'Pave'.\n",
    "\n",
    "\n",
    "\n",
    "4)-> LotShape:\n",
    "properties with an 'IR2' (moderately irregular-shaped) lot have the highest impact on the target variable SalePrice, followed by 'IR3' (highly irregular) 'IR1' (slightly irregular), and then 'Reg' (regular-shaped) lots. This order indicates a perceived association between lot irregularity and the SalePrice\n",
    "\n",
    "\n",
    "\n",
    "5)-> LandCounter:\n",
    "'Lvl': Indicates properties with a level (flat) contour.\n",
    "\n",
    "'Bnk': Represents properties with a banked contour (a slope).\n",
    "\n",
    "'Low': Signifies properties with a low contour (depression).\n",
    "\n",
    "'HLS': Represents properties with a hillside contour.\n",
    "\n",
    "    \n",
    "High Impact on SalePrice:\n",
    "\n",
    "Properties with 'HLS' (hillside) land contour have the highest impact on SalePrice.\n",
    "\n",
    "Second-Highest Impact:\n",
    "\n",
    "'Low' contour properties (depression) come next in impacting SalePrice positively.\n",
    "\n",
    "Moderate Impact:\n",
    "\n",
    "'Lvl' contour properties (level or flat) show a moderate impact on SalePrice.\n",
    "\n",
    "Lowest Impact:\n",
    "\n",
    "'Bnk' contour properties (banked or sloped) have the least impact on SalePrice.\n",
    "\n",
    "\n",
    "\n",
    "6)->Utilities:\n",
    "AllPub (All Public):\n",
    "\n",
    "Properties with 'AllPub' utilities have the strongest impact on the target variable SalePrice.\n",
    "\n",
    "NoSewa (No Seperate Water and Electricity):\n",
    "\n",
    "Properties with 'NoSeWa' utilities have a moderate impact on SalePrice.\n",
    "\n",
    "'AllPub' (All Public Utilities) category in the 'Utilities' variable has the strongest positive impact on the target variable SalePrice, while 'NoSeWa' (No Separate Water and Electricity) has a moderate impact. This implies that properties with access to all standard public utilities may be associated with higher sale prices compared to properties with limited utility services.\n",
    "\n",
    "\n",
    "\n",
    "7)->LotConfig:\n",
    "The 'LotConfig' variable describes the lot configuration of properties in dataset:\n",
    "\n",
    "'Inside': Properties with lot configurations positioned inside the neighborhood.\n",
    "\n",
    "'FR2': Properties with lot configurations adjacent to a feeder road.\n",
    "\n",
    "'Corner': Properties with lot configurations at a street corner.\n",
    "\n",
    "'CulDSac': Properties with lot configurations at the end of a cul-de-sac.\n",
    "\n",
    "'FR3': Properties with lot configurations adjacent to a feeder road on three sides.\n",
    "\n",
    "'CulDSac' Configuration:\n",
    "\n",
    "Properties with a 'CulDSac' lot configuration have the highest impact on the sale price.\n",
    "\n",
    "'FR3' Configuration:\n",
    "\n",
    "Properties with an 'FR3' (adjacent to a feeder road on three sides) lot configuration have the second-highest impact on the sale price.\n",
    "\n",
    "Similar Impact:\n",
    "\n",
    "The 'Inside,' 'FR2' (adjacent to a feeder road), and 'Corner' lot configurations have a similar impact on the sale price.\n",
    "\n",
    "This suggests that the specific layout and positioning of properties within their neighborhoods may play a role in influencing their sale prices.\n",
    "\n",
    "\n",
    "\n",
    "8)->LandSlope:\n",
    "The 'LandSlope' variable describes the slope of the property in dataset:\n",
    "\n",
    "'Gtl': Represents properties with a gentle slope.\n",
    "\n",
    "'Mod': Represents properties with a moderate slope.\n",
    "\n",
    "'Sev': Represents properties with a severe slope.\n",
    "\n",
    "'Gtl' (gentle slope) and 'Mod' (moderate slope) has same impact on sale price.\n",
    "\n",
    "'Sev' (severe slope) has a slightly higher impact on sale price.\n",
    "\n",
    "This implies that properties with more severe slopes may be associated with a slightly higher impact on sale prices compared to properties with gentle or moderate slopes.\n",
    "\n",
    "\n",
    "\n",
    "9)-> Neighborhood:\n",
    "our observation suggests that, in our dataset, the neighborhood labeled 'NoRidge' has the highest impact on house prices.\n",
    "\n",
    "\n",
    "10)-> Condition1:\n",
    "Here's a brief description of each value in the 'Condition1' variable:\n",
    "\n",
    "'Norm': Properties in a normal proximity to main roads or railroads.\n",
    "\n",
    "'Feedr': Properties facing a feeder road, which is a smaller road that provides access to properties.\n",
    "\n",
    "'PosN': Properties located near a positive feature, such as a park.\n",
    "\n",
    "'Artery': Properties adjacent to an arterial road, a more significant road.\n",
    "\n",
    "'RRAe': Properties with a rear easement, indicating a railroad at the rear.\n",
    "\n",
    "'RRNn': Properties with a railroad nearby to the north.\n",
    "\n",
    "'RRAn': Properties with a railroad nearby to the northwest.\n",
    "\n",
    "'PosA': Properties located near a positive feature, such as a park (similar to 'PosN').\n",
    "\n",
    "'RRNe': Properties with a railroad nearby to the northeast.\n",
    "\n",
    "These values describe different conditions related to the proximity of properties to main roads or railroads, providing insights into their locations and potential influences on property values.\n",
    "\n",
    "'PosA' (proximity to a positive feature such as a park),\n",
    "\n",
    "'PosN' (proximity to a positive feature, similar to 'PosA'),\n",
    "\n",
    "'RRNn' (proximity to a railroad to the north),\n",
    "\n",
    "have a high impact on the target variable SalePrice. This suggests that properties with these conditions in their proximity may be associated with higher sale prices.\n",
    "\n",
    "\n",
    "\n",
    "11)->Condition2:\n",
    "our observation suggests that in the 'Condition2' variable:\n",
    "\n",
    "'PosA' (proximity to a positive feature, similar to a park) and\n",
    "\n",
    "'PosN' (proximity to a positive feature, such as a park)\n",
    "\n",
    "have a high impact on the target variable SalePrice.\n",
    "\n",
    "\n",
    "\n",
    "12)->BldgType:\n",
    "The 'BldgType' variable describes different types of dwellings in the dataset:\n",
    "\n",
    "'1Fam': Single-family homes.\n",
    "\n",
    "'2fmCon': Two-family conversion (duplex).\n",
    "\n",
    "'Duplex': Duplexes.\n",
    "\n",
    "'TwnhsE': Townhouses inside a building.\n",
    "\n",
    "'Twnhs': Townhouses in rows.\n",
    "\n",
    "These values indicate the structural characteristics or types of residential buildings in the dataset.\n",
    "\n",
    "our observation suggests that, in our dataset:\n",
    "\n",
    "'1Fam' (Single-family homes) and\n",
    "\n",
    "'TwnhsE' (Townhouses inside a building)\n",
    "\n",
    "have the highest impact on the target variable, indicating that these types of dwellings may be associated with higher values in the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d59376",
   "metadata": {},
   "source": [
    "### Multi-variate Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57acb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "continous_feat = data[['LotArea','BsmtFinSF1','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','SalePrice']]\n",
    "sns.set(style = 'ticks')\n",
    "sns.pairplot(continous_feat, diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ead3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continous_feat.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad34a4",
   "metadata": {},
   "source": [
    "##### Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931df053",
   "metadata": {},
   "source": [
    "High Correlations with SalePrice:\n",
    "Features with relatively high positive correlations with SalePrice include:\n",
    "\n",
    "\n",
    "TotalBsmtSF (0.613581)\n",
    "GrLivArea (0.708624)\n",
    "GarageArea (0.623431)\n",
    "These features might have a strong influence on the SalePrice. Consider exploring these relationships further, and they could potentially be important predictors.\n",
    "\n",
    "\n",
    "\n",
    "Correlation between Features:\n",
    "TotalBsmtSF and 1stFlrSF show a high correlation of 0.819530. This is not surprising, as the total basement area and the first floor area are likely to be correlated.\n",
    "\n",
    "GrLivArea and 2ndFlrSF also exhibit a strong correlation of 0.687501. This makes sense since the living area above ground and the second floor area are related.\n",
    "\n",
    "GarageArea and TotalBsmtSF, as well as GarageArea and 1stFlrSF, show notable correlations. It suggests that the garage area is correlated with both the total basement area and the first floor area.\n",
    "\n",
    "\n",
    "\n",
    "Low Correlations:\n",
    "LotArea shows relatively low correlations with the other features. It might not have a strong linear relationship with the other variables.\n",
    "\n",
    "\n",
    "Potential Multicollinearity:\n",
    "TotalBsmtSF, 1stFlrSF, and GarageArea all have relatively high correlations with each other. When using these features in a predictive model, multicollinearity might need to be considered.\n",
    "\n",
    "\n",
    "Negative Correlation:\n",
    "2ndFlrSF has a negative correlation with BsmtFinSF1 (-0.137079). This suggests that as the finished square feet of the basement increase, the second floor square footage tends to decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07de30f",
   "metadata": {},
   "source": [
    "#### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8de474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cheking null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56678860",
   "metadata": {},
   "source": [
    "#### lets check how many column have null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b808a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_null = data.columns[data.isnull().any()]\n",
    "number_of_column_nv = len(column_with_null)\n",
    "print(\"Number of columns with  null values :\",number_of_column_nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ec016",
   "metadata": {},
   "source": [
    "#### lets see these 19 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[column_with_null].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6599c",
   "metadata": {},
   "source": [
    "#### Handling null values in continous data and replacing it with median value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_impute = ['LotFrontage','MasVnrArea','GarageYrBlt']\n",
    "\n",
    "for col in col_to_impute:\n",
    "    median_value = data[column].median()\n",
    "    data[col].fillna(median_value, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8b4fc",
   "metadata": {},
   "source": [
    "#### Handling null values in categorical data and replacing it with mode value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c10be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_impute = ['Alley', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "       'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu',\n",
    "       'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC',\n",
    "       'Fence', 'MiscFeature']\n",
    "\n",
    "for column in cols_to_impute:\n",
    "    mode_value = data[column].mode().iloc[0]\n",
    "    data[column].fillna(mode_value, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092583f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35c69d",
   "metadata": {},
   "source": [
    "### Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31001b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_Encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_encod = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
    "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
    "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
    "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
    "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "       'SaleType', 'SaleCondition']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in col_to_encod:\n",
    "    data[column] = label_Encoder.fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a02462",
   "metadata": {},
   "source": [
    "#### Handling Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results for each column\n",
    "outlier_info = {}\n",
    "\n",
    "# Iterate through each column in your dataset\n",
    "for cols in data_continous.columns:\n",
    "    # Calculate statistics for the current column\n",
    "    Q1 = data_continous[cols].quantile(0.25)\n",
    "    Q3 = data_continous[cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Calculate the count of values greater than max_limit and less than min_limit for the current column\n",
    "    cnt_greater_max = (data_continous[cols] > (Q3 + 1.5 * IQR)).sum()\n",
    "    cnt_less_min = (data_continous[cols] < (Q1 - 1.5 * IQR)).sum()\n",
    "\n",
    "    # Calculate the percentage of values greater than max_limit and less than min_limit for the current column\n",
    "    percent_greater_max = (cnt_greater_max / len(data)) * 100\n",
    "    percent_less_min = (cnt_less_min / len(data)) * 100\n",
    "\n",
    "    # Store the results in the dictionary\n",
    "    outlier_info[cols] = {\n",
    "        'count_greater_max': cnt_greater_max,\n",
    "        'percent_greater_max': percent_greater_max,\n",
    "        'count_less_min': cnt_less_min,\n",
    "        'percent_less_min': percent_less_min\n",
    "    }\n",
    "\n",
    "# Print the results for each column\n",
    "for column, info in outlier_info.items():\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Count Greater Than max_limit: {info['count_greater_max']}\")\n",
    "    print(f\"Percent Greater Than max_limit: {info['percent_greater_max']:.2f}%\")\n",
    "    print(f\"Count Less Than min_limit: {info['count_less_min']}\")\n",
    "    print(f\"Percent Less Than min_limit: {info['percent_less_min']:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e526d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for cols in data_continous[:-1]:\n",
    "    if plotnumber<=15 :    \n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.boxplot(x=data_continous[cols])\n",
    "        plt.xlabel(cols,fontsize=10)\n",
    "    \n",
    "    plotnumber+=1\n",
    "    plt.xticks(rotation=90,fontsize=7)\n",
    "        \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3971166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7cda10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_continous.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06052ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b297ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_data = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "       'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "       'ScreenPorch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data[continous_data].quantile(0.25)\n",
    "Q3 = data[continous_data].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "min_limit = Q1 - 1.5 * IQR\n",
    "max_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "data[continous_data] = np.where (\n",
    "    (data[continous_data] < min_limit) | (data[continous_data] > max_limit),\n",
    "    data[continous_data].median(), data[continous_data]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efea3e",
   "metadata": {},
   "source": [
    "### Handling Outlier discrete data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460fca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_data = ['MSZoning','Street','Alley','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "            'Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType',\n",
    "            'ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating',\n",
    "            'HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish',\n",
    "            'GarageQual','GarageCond','PavedDrive','PoolQC','Fence','MiscFeature','SaleType','SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 25), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "for column in data_discrete.columns[:-1]:\n",
    "    plt.subplot(6,3, plotnumber)\n",
    "    sns.boxplot(x = data[column])\n",
    "    \n",
    "    plt.xlabel(column, fontsize = 10)\n",
    "    plt.ylabel('Counts' , fontsize = 10)\n",
    "    plotnumber += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data[discrete_data].quantile(0.25)\n",
    "Q3 = data[discrete_data].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "min_limit = Q1 - 1.5 * IQR\n",
    "max_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "data[discrete_data] = np.where((data[discrete_data]< min_limit) | (data[discrete_data]> max_limit),\n",
    "                              data[discrete_data].mode().iloc[0], data[discrete_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116da564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see  whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e90133",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab238ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns[:-1]:\n",
    "    sns.boxplot(x =data[column])\n",
    "    plt.title(f\"{column} Boxplot\")\n",
    "    plt.xlabel(column, fontsize = 10)\n",
    "    plt.ylabel('Limits', fontsize = 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28365ca",
   "metadata": {},
   "source": [
    "## Feature Engineering:\n",
    "- Definition:\n",
    "  Feature engineering involves transforming or creating new features from raw data to enhance machine learning model performance.\n",
    "\n",
    "-  Simplification:\n",
    "   Simplify complex relationships in the data, making it easier for models to understand.\n",
    "\n",
    "- Improved Model Performance:\n",
    "  Enhance model accuracy and predictive power by providing more relevant and informative input features.\n",
    "\n",
    "\n",
    "- Addressing Non-Linearity:\n",
    "  Capture non-linear relationships between features and the target variable, enabling models to learn more complex patterns.\n",
    "\n",
    "- Handling Missing Data:\n",
    "  Fill or transform missing values in a meaningful way to prevent information loss during model training.\n",
    "\n",
    "- Dimensionality Reduction:\n",
    "  Reduce the number of features, especially in high-dimensional datasets, to avoid overfitting and speed up model training.\n",
    "\n",
    "- Creating Composite Features:\n",
    "  Generate new features by combining or interacting existing ones, providing additional information to the model.\n",
    "\n",
    "- Temporal and Spatial Insights:\n",
    "  Incorporate time or spatial components to reveal trends, patterns, or seasonality in the data.\n",
    "\n",
    "- Enhanced Interpretability:\n",
    "  Make models more interpretable by transforming features into more understandable or representative formats.\n",
    "\n",
    "- Optimizing Model Resources:\n",
    "  Save computational resources by excluding irrelevant or redundant features, making models more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98990d93",
   "metadata": {},
   "source": [
    "##### Age of House at Sale time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_at_sale'] = data['YrSold'] - data['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain both 'YrSold' and 'YearBuilt' for context and potential further analysis.\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = data.Age_at_sale, y = data.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38020518",
   "metadata": {},
   "source": [
    "- The code creates a new binary column 'Remodeled' in the DataFrame df, where the value is 1 if the house has been \n",
    "remodeled (if 'YearBuilt' is different from 'YearRemodAdd'), and 0 otherwise\n",
    "# ......................................................................................................................\n",
    "- Finding whether a house has been remodeled is essential as it provides insights into property history and condition, impacting sale price by influencing perceived value and desirability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad773b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Remodeld'] = (data['YearBuilt'] != data['YearRemodAdd']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = data.Remodeld, y = data.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163246c2",
   "metadata": {},
   "source": [
    "##### Total square footage:\n",
    "- Finding the total square footage combines the areas of the first and second floors, providing a comprehensive measure of living space that influences the property's size and, consequently, its sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['totalSF'] =data['1stFlrSF'] + data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = data.totalSF, y= data.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326929a",
   "metadata": {},
   "source": [
    "##### Total Bathrooms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b905d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalBath'] = data['FullBath'] + data['HalfBath'] + data['BsmtFullBath'] + data['BsmtHalfBath'] * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b317f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = data.TotalBath, y = data.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df29b11",
   "metadata": {},
   "source": [
    "- The multiplication by 0.5 is applied to the 'BsmtHalfBath' column. It signifies that each half bathroom in the basement ('BsmtHalfBath') contributes half of a full bathroom to the total count. This adjustment ensures an accurate representation of the total number of bathrooms in the 'TotalBathrooms' column, considering both full and half bathrooms throughout the house.\n",
    "- 'TotalBathrooms' adequately captures the bathroom-related information of our regression model and there are no specific reasons to retain individual columns, dropping them could simplify your feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed9580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7800de4",
   "metadata": {},
   "source": [
    "#### Outdoor living area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36620c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "porch_deck_features = ['WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']\n",
    "data['Outdoor_LA'] = data[porch_deck_features].sum(axis = 1)\n",
    "\n",
    "\n",
    "# # lets check correlation of above created column\n",
    "cr = data['Outdoor_LA'].corr(data['SalePrice'])\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = data.Outdoor_LA , y= data.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a793168",
   "metadata": {},
   "source": [
    "##### Over condition score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd642fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quality_condition_score'] = data['OverallQual'] + data['OverallCond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets the corelation of quality_condition_score with target variable \n",
    "corr = data['quality_condition_score'].corr(data['SalePrice'])\n",
    "print('Quality_condition_score correlation with target variable ::',corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9227032",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x =data.quality_condition_score, y = data.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr1 = data['OverallQual'].corr(data['SalePrice'])\n",
    "print(cr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e34aac",
   "metadata": {},
   "source": [
    "- A correlation coefficient of 0.67 is generally considered a strong positive correlation, indicating a substantial relationship between the two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ac3e1",
   "metadata": {},
   "source": [
    "##### Total Basement Area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1501b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_area_feature = ['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF']\n",
    "data['Total_bmt_area'] = data[bsmt_area_feature].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857dcf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot( x =data.Total_bmt_area, y= data.SalePrice )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6f8fc",
   "metadata": {},
   "source": [
    "### Created_feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52774859",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_feature = data[['Age_at_sale','totalSF','TotalBath','Outdoor_LA','quality_condition_score','Total_bmt_area','Remodeld']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463578f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b081cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 25), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "for column in created_feature.columns:\n",
    "    if plotnumber <= 7:\n",
    "        plt.subplot(4,2, plotnumber)\n",
    "        sns.scatterplot(x = created_feature[column], y =data.SalePrice)\n",
    "        \n",
    "        plt.title(f'{column} vs SalePrice')\n",
    "        plt.xlabel(column, fontsize = 10)\n",
    "        plt.ylabel('SalePrice', fontsize = 10)\n",
    "        plotnumber += 1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c568c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.SalePrice\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73706ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2  = pd.concat([created_feature , y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f79c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7143a7",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "- Age_at_sale and SalePrice: There is a negative correlation (-0.53), indicating that as the age at sale increases, the sale price tends to decrease.\n",
    "\n",
    "- TotalSF and SalePrice: There is a positive correlation (0.64), suggesting that as the total square footage increases, the sale price tends to increase.\n",
    "\n",
    "- TotalBath and SalePrice: Positive correlation (0.62), indicating that houses with more bathrooms tend to have higher sale prices.\n",
    "\n",
    "- Outdoor_LA and SalePrice: Positive correlation (0.41), suggesting that a larger outdoor living area is associated with higher sale prices.\n",
    "\n",
    "- Quality_Condition_Score and SalePrice: Strong positive correlation (0.68), indicating that houses with higher quality and condition scores tend to have higher sale prices.\n",
    "\n",
    "- Total_bmt_area and SalePrice: Positive correlation (0.50), suggesting that a larger basement area is associated with higher sale prices.\n",
    "\n",
    "- Remodeled and SalePrice: Positive correlation (although weak) (0.02), suggesting that remodeled houses might have slightly higher sale prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c53705",
   "metadata": {},
   "source": [
    "## Feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking correlation\n",
    "\n",
    "plt.figure(figsize=(50, 40))#canvas size\n",
    "sns.heatmap(data_numerical.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})#plotting heat map to check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeab77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data_numerical.corr()[['SalePrice']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation with SalePrice - House Price Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91021339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation feature Selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328aac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_corr = data.corr()[['SalePrice']]\n",
    "plt.figure(figsize= (10, 25))\n",
    "sns.heatmap(target_corr, annot = True, cmap = plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277dfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print only  those column which have corr greater than 0.5\n",
    "target_corr[abs(target_corr)>0.5].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5aaf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('SalePrice', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a841754",
   "metadata": {},
   "source": [
    "#### 2nd Feature selection Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3b0ff",
   "metadata": {},
   "source": [
    "L1 regularization, also known as Lasso regularization, is a technique in machine learning that penalizes large model weights during training. Its main goal is to encourage the model to use fewer features by driving some feature weights to exactly zero.\n",
    "\n",
    "In the context of linear models, the regularization involves adding a penalty term to the original cost function. This penalty term, controlled by a parameter (λ), promotes sparsity by discouraging large weights. During training, the optimization algorithm minimizes the regularized cost function, resulting in some feature weights becoming zero.\n",
    "\n",
    "Why use L1 regularization:\n",
    "\n",
    "Feature Selection: L1 regularization naturally selects important features by driving less important ones to have zero weights, making the model more interpretable and efficient.\n",
    "\n",
    "Multicollinearity Handling: It can handle high correlations between features by selecting one from a group of correlated features and setting others' weights to zero.\n",
    "\n",
    "Simplifying Models: L1 regularization aids in creating simpler models that generalize better to new data, preventing overfitting and overly complex models.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "Automatic Feature Selection: L1 regularization automatically selects relevant features without manual engineering.\n",
    "\n",
    "Improved Generalization: By promoting sparsity, it helps prevent overfitting and enhances the model's ability to generalize to new, unseen data.\n",
    "\n",
    "Interpretability: Sparse models are easier to interpret as they focus on a subset of the most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da93d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rnd = RandomForestRegressor(n_estimators=10)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc2b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_ = SelectFromModel(RandomForestRegressor(n_estimators=10,random_state=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feat = X_train.columns[(sel_.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(select_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0acb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['OverallQual', 'YearRemodAdd', 'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF',\n",
    "       'GrLivArea','LotArea','2ndFlrSF' ,'FullBath', 'GarageCars', 'GarageArea',\n",
    "       'totalSF', 'TotalBath', 'Total_bmt_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac040dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([X,y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20,20))\n",
    "sns.heatmap(data1.corr(), annot = True,cmap = 'RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c2cb0",
   "metadata": {},
   "source": [
    "### Split Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273738aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb977bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25c5d1",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "\n",
    "## Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aea5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor #importing decision tree from sklearn.tree\n",
    "\n",
    "dt=DecisionTreeRegressor() # object creation for decision tree\n",
    "\n",
    "dt.fit(X_train,y_train) # training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5430b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "import math\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_dt):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_dt):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_dt):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_dt):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = dt.predict(X_train)\n",
    "print(f'R2 Score: {r2_score(y_train, y_train_predict):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e9230",
   "metadata": {},
   "source": [
    "### Hyper paramter tuning for Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45c218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"criterion\":('friedman_mse', 'poisson', 'squared_error', 'absolute_error'), #quality of split\n",
    "    \"splitter\":(\"best\", \"random\"), # searches the features for a split\n",
    "    \"max_depth\":(list(range(1, 20))), #depth of tree range from 1 to 19\n",
    "    \"min_samples_split\":[2,20],    #the minimum number of samples required to split internal node\n",
    "    \"min_samples_leaf\":list(range(1, 20)),#minimum number of samples required to be at a leaf node,we are passing list which is range from 1 to 19\n",
    "}\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=3)#object creation for decision tree with random state 3\n",
    "tree_cv = GridSearchCV(tree_reg, params, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1, cv=3)\n",
    "#passing model to gridsearchCV ,\n",
    "#tree_clf-->model\n",
    "#params---->hyperparametes(dictionary we created)\n",
    "#scoring--->performance matrix to check performance\n",
    "#n_jobs---->Number of jobs to run in parallel,-1 means using all processors.\n",
    "#verbose=Controls the verbosity: the higher, the more messages.\n",
    "#>1 : the computation time for each fold and parameter candidate is displayed;\n",
    "#>2 : the score is also displayed;\n",
    "#>3 : the fold and candidate parameter indexes are also displayed together with the starting time of the computation.\n",
    "#cv------> number of flods\n",
    "\n",
    "tree_cv.fit(X_train,y_train)#training data on gridsearch cv\n",
    "best_params = tree_cv.best_params_ #it will give you best parameters\n",
    "print(f\"Best paramters: {best_params})\")#printing  best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n",
    "tree_cv.best_params_#getting best parameters from cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d726fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_score_#getting best score form cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_h=DecisionTreeRegressor(criterion='friedman_mse',max_depth=10,min_samples_leaf= 4,min_samples_split=20,splitter='random')#passing best parameter to decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_h.fit(X_train,y_train)#traing model with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1eb809",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dth=dt_h.predict(X_test)#predicting\n",
    "y_pred_dth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a994cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_dth):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_dth):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_dth):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_dth):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb35879",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = dt_h.predict(X_train)\n",
    "print(f'R2 Score: {r2_score(y_train, y_train_predict):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d27a297",
   "metadata": {},
   "source": [
    "## Random Forest- Ensemble Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf=rf.predict(X_test)\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_rf):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_rf):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_rf):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_rf):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9933562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking cross validation score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_scores = cross_val_score(rf, X_train, y_train, cv=3, scoring='r2')\n",
    "print(r2_scores)\n",
    "# Print mean and standard deviation of R-squared scores\n",
    "print(\"Random Forest Regressor Cross-Validation R-squared Scores:\")\n",
    "print(\"Mean R-squared:\", np.mean(r2_scores))\n",
    "print(\"Standard Deviation of R-squared:\", np.std(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5a2a2",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c713b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3714e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=50, stop=200, num=10)],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at each split\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist, n_iter=10, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators= 66, min_samples_split= 2, min_samples_leaf= 2, max_features= 'sqrt', max_depth= None, bootstrap= False)#passing best parameter to randomforest\n",
    "\n",
    "rf_reg.fit(X_train,y_train)#training\n",
    "\n",
    "y_rf_reg=rf_reg.predict(X_test)#testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "import math\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_rf_reg):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_rf_reg):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_rf_reg):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_rf_reg):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a8f20",
   "metadata": {},
   "source": [
    "# XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f83a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd27d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm=GradientBoostingRegressor() ## object creation\n",
    "gbm.fit(X_train,y_train) ## fitting the data\n",
    "y_gbm=gbm.predict(X_test) ## predicting the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_gbm):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_gbm):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_gbm):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_gbm):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae33761",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor#importing the model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bafca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_r=XGBRegressor() ## object creation\n",
    "xgb_r.fit(X_train,y_train)# fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251cfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb=xgb_r.predict(X_test) # predicting the strength of concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1398cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb=xgb_r.predict(X_test) # predicting the strength of concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_xgb):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_xgb):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_xgb):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_xgb):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a54051",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning for XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "XGB=XGBRegressor(random_state=42,verbosity=0,silent=0)\n",
    "rcv= RandomizedSearchCV(estimator=XGB, scoring='neg_mean_absolute_error',param_distributions=param_grid, n_iter=100, cv=3,\n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "#estimator--number of decision tree\n",
    "#scoring--->performance matrix to check performance\n",
    "#param_distribution-->hyperparametes(dictionary we created)\n",
    "#n_iter--->Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.default=10\n",
    "##cv------> number of flods\n",
    "#verbose=Controls the verbosity: the higher, the more messages.\n",
    "#n_jobs---->Number of jobs to run in parallel,-1 means using all processors.\n",
    "\n",
    "rcv.fit(X_train, y_train)##training data on randomsearch cv\n",
    "cv_best_params = rcv.best_params_##it will give you best parameters\n",
    "print(f\"Best paramters: {cv_best_params})\")##printing  best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a652be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB2=XGBRegressor(reg_lambda= 12.8, reg_alpha= 0.1, n_estimators=150, max_depth=5, learning_rate=0.1, gamma=0.8)\n",
    "XGB2.fit(X_train, y_train)#training\n",
    "y_predict_xgb2=XGB2.predict(X_test) # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd89b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_predict_xgb2):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_predict_xgb2):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_predict_xgb2):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_predict_xgb2):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1249f6",
   "metadata": {},
   "source": [
    "### Model  Creation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8495305",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd41f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tr = DecisionTreeRegressor()\n",
    "d_tr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = d_tr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8299b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_r2 = r2_score(y_test, y_hat)\n",
    "print('Decision tree R2_score :', d_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trianing score of Decision Tree:\n",
    "y_pred_train = d_tr.predict(X_train)\n",
    "\n",
    "train_r2_score = r2_score(y_train, y_pred_train)\n",
    "print('Training score :',train_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961ceca",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0447e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770bbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'criterion':('friedman_mse','poisson', 'squared_error', 'absolute_error'),\n",
    "    'splitter':('best','random'),\n",
    "    'max_depth':(list(range(1, 20))),\n",
    "    'min_samples_split':[2,3,5,19,20],\n",
    "    'min_samples_leaf':(list(range(1, 20)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e614fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeRegressor(random_state=42)\n",
    "tree_gv = GridSearchCV(d_tree,param, scoring = 'neg_mean_squared_error',n_jobs = -1 ,cv = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d947f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_gv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter :\",tree_gv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8829c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best estimators :\",tree_gv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dee7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tr = DecisionTreeRegressor(criterion= 'friedman_mse', max_depth= 8, min_samples_leaf = 3, min_samples_split= 20, splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a588d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hyp_t= de_tr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa849a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_r2_dtree =r2_score(y_test, y_hyp_t)\n",
    "print(\"r2_score of Decision tree after hyper parameter tuning :\",hyper_r2_dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba7f16",
   "metadata": {},
   "source": [
    "### RandomForest Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ecf0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=400)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ee585",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb81e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_r2 = r2_score(y_test, y_pred)\n",
    "print(\"Random Forest Regressor R2_score :\",rn_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Score:\n",
    "y_rfr_train = d_tr.predict(X_train)\n",
    "\n",
    "train_r2_score = r2_score(y_train, y_rfr_train)\n",
    "print('Training score of Random Forest Regressor:',train_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be6166",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for randomForestRegressor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e75545",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868acee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':[int(x) for x in np.linspace(100, 2100, num= 13)],\n",
    "    'max_features':['auto', 'sqrt','log2',None],\n",
    "    'max_depth':[None]+[int(x) for x in np.linspace(10, 110, num= 11)],\n",
    "    'min_samples_split':[2,5,10],\n",
    "    'min_samples_leaf':[1,2,4],\n",
    "    'bootstrap' : [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rf = RandomForestRegressor(n_estimators=400)\n",
    "rf_cv = RandomizedSearchCV(Rf, param_distributions = param_grid,scoring ='neg_mean_squared_error' ,n_iter = 100, cv =5,n_jobs = -1 ,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd656e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameter from random forest regressor :',rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best estimator of randomforest regressor :',rf_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98432f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_reg  = RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,\n",
    "                      min_samples_split=10, n_estimators=1933)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbdf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hyp_rf = rand_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa69cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyp_r2 = r2_score(y_test, y_hyp_rf)\n",
    "rf_hyp_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4c001",
   "metadata": {},
   "source": [
    "### XGBRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c260c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d41acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_r2 = r2_score(y_test, y_hat_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4680f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBRegressor R2_score :\",xgb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e125dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training score:\n",
    "y_xgb_train = d_tr.predict(X_train)\n",
    "\n",
    "train_r2_score = r2_score(y_train, y_xgb_train)\n",
    "print('Training score  of XGBRegressor:',train_r2_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db2d80",
   "metadata": {},
   "source": [
    "## Hyper parameter Tuning of XGBRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25446edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf728c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91052ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gbr = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edfa869",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_r2 = r2_score(y_test, y_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ea14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boosting Regressor r2_score :\",gbr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b9644",
   "metadata": {},
   "source": [
    "# Adaboostregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edf877",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = AdaBoostRegressor(n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f41060",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ad = ad.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2971fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc42eb",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],  # Number of weak learners (trees)\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],  # Shrinkage parameter\n",
    "    'loss': ['linear', 'square', 'exponential']  # Loss function to minimize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54964f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "add = AdaBoostRegressor(n_estimators=100)\n",
    "ad_reg = GridSearchCV(add, param_grid=param_grid, scoring= 'r2', n_jobs = -1, cv =3, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ba375",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameter of AdaBoostRegressor :',ad_reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best estimator of AdaBoostregressor :',ad_reg.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70477173",
   "metadata": {},
   "outputs": [],
   "source": [
    "adda = AdaBoostRegressor(learning_rate=1, loss='exponential')\n",
    "adda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hyp_add = adda.predict(X_test)\n",
    "y_hyp_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_hyp_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4058a",
   "metadata": {},
   "source": [
    "## Model Creation with Engineered Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a5f1a",
   "metadata": {},
   "source": [
    "### Decision Tree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X2,y,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d36b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor #importing decision tree from sklearn.tree\n",
    "\n",
    "dt=DecisionTreeRegressor() # object creation for decision tree\n",
    "\n",
    "dt.fit(X_train,y_train) # training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c88aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad470ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "import math\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_dt):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_dt):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_dt):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_dt):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b56c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = dt.predict(X_train)\n",
    "print(f'R2 Score: {r2_score(y_train, y_train_predict):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d0296",
   "metadata": {},
   "source": [
    "### Hyper paramter tuning for Decision tree2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"criterion\":('friedman_mse', 'poisson', 'squared_error', 'absolute_error'), #quality of split\n",
    "    \"splitter\":(\"best\", \"random\"), # searches the features for a split\n",
    "    \"max_depth\":(list(range(1, 20))), #depth of tree range from 1 to 19\n",
    "    \"min_samples_split\":[2,20],    #the minimum number of samples required to split internal node\n",
    "    \"min_samples_leaf\":list(range(1, 20)),#minimum number of samples required to be at a leaf node,we are passing list which is range from 1 to 19\n",
    "}\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=3)#object creation for decision tree with random state 3\n",
    "tree_cv = GridSearchCV(tree_reg, params, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1, cv=3)\n",
    "#passing model to gridsearchCV ,\n",
    "#tree_clf-->model\n",
    "#params---->hyperparametes(dictionary we created)\n",
    "#scoring--->performance matrix to check performance\n",
    "#n_jobs---->Number of jobs to run in parallel,-1 means using all processors.\n",
    "#verbose=Controls the verbosity: the higher, the more messages.\n",
    "#>1 : the computation time for each fold and parameter candidate is displayed;\n",
    "#>2 : the score is also displayed;\n",
    "#>3 : the fold and candidate parameter indexes are also displayed together with the starting time of the computation.\n",
    "#cv------> number of flods\n",
    "\n",
    "tree_cv.fit(X_train,y_train)#training data on gridsearch cv\n",
    "best_params = tree_cv.best_params_ #it will give you best parameters\n",
    "print(f\"Best paramters: {best_params})\")#printing  best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a395f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n",
    "tree_cv.best_params_#getting best parameters from cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_score_#getting best score form cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de63edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_h=DecisionTreeRegressor(criterion='poisson',max_depth=12,min_samples_leaf= 1,min_samples_split=2,splitter='best')#passing best parameter to decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_h.fit(X_train,y_train)#traing model with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88002422",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dth=dt_h.predict(X_test)#predicting\n",
    "y_pred_dth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_dth):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_dth):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_dth):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_dth):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5642b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = dt_h.predict(X_train)\n",
    "print(f'R2 Score: {r2_score(y_train, y_train_predict):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab51f8",
   "metadata": {},
   "source": [
    "## Random Forest- Ensemble Technique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf=rf.predict(X_test)\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e99a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_rf):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_rf):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_rf):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_rf):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09831904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking cross validation score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_scores = cross_val_score(rf, X_train, y_train, cv=3, scoring='r2')\n",
    "print(r2_scores)\n",
    "# Print mean and standard deviation of R-squared scores\n",
    "print(\"Random Forest Regressor Cross-Validation R-squared Scores:\")\n",
    "print(\"Mean R-squared:\", np.mean(r2_scores))\n",
    "print(\"Standard Deviation of R-squared:\", np.std(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019eb6b0",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for Randomforest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd147b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699fd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=50, stop=200, num=10)],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at each split\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist, n_iter=10, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef75f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce15173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9338b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators= 50, min_samples_split= 10, min_samples_leaf= 2, max_features= 'auto', max_depth= 30, bootstrap= False)#passing best parameter to randomforest\n",
    "\n",
    "rf_reg.fit(X_train,y_train)#training\n",
    "\n",
    "y_rf_reg=rf_reg.predict(X_test)#testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75608c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "import math\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_rf_reg):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_rf_reg):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_rf_reg):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_rf_reg):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b1d19",
   "metadata": {},
   "source": [
    "# XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0112a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm=GradientBoostingRegressor() ## object creation\n",
    "gbm.fit(X_train,y_train) ## fitting the data\n",
    "y_gbm=gbm.predict(X_test) ## predicting the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb43170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_gbm):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_gbm):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_gbm):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_gbm):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d66d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_r=XGBRegressor() ## object creation\n",
    "xgb_r.fit(X_train,y_train)# fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cc3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb=xgb_r.predict(X_test) # predicting the strength of concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ce4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_pred_xgb):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_pred_xgb):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred_xgb):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_xgb):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ec1b7",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning for XGBoost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3957540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "XGB=XGBRegressor(random_state=42,verbosity=0,silent=0)\n",
    "rcv= RandomizedSearchCV(estimator=XGB, scoring='neg_mean_absolute_error',param_distributions=param_grid, n_iter=100, cv=3,\n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "#estimator--number of decision tree\n",
    "#scoring--->performance matrix to check performance\n",
    "#param_distribution-->hyperparametes(dictionary we created)\n",
    "#n_iter--->Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.default=10\n",
    "##cv------> number of flods\n",
    "#verbose=Controls the verbosity: the higher, the more messages.\n",
    "#n_jobs---->Number of jobs to run in parallel,-1 means using all processors.\n",
    "\n",
    "rcv.fit(X_train, y_train)##training data on randomsearch cv\n",
    "cv_best_params = rcv.best_params_##it will give you best parameters\n",
    "print(f\"Best paramters: {cv_best_params})\")##printing  best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce138d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB2=XGBRegressor(reg_lambda= 0, reg_alpha= 200, n_estimators=100, max_depth=6, learning_rate=0.2, gamma=3.2)\n",
    "XGB2.fit(X_train, y_train)#training\n",
    "y_predict_xgb2=XGB2.predict(X_test) # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Accuracy score\n",
    "\n",
    "print(f'Test Mean Squared Error: {mean_squared_error(y_test,y_predict_xgb2):.5f}')\n",
    "print(f'Test Mean Absolute Error: {mean_absolute_error(y_test, y_predict_xgb2):.5f}')\n",
    "print(f'Test Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_predict_xgb2):.5f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_predict_xgb2):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7df0f",
   "metadata": {},
   "source": [
    "# Model Performance Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming compiled_results is your DataFrame\n",
    "data = {\n",
    "    'Model': ['DT', 'DT_H','RF','RF_H','XGB', 'XGBoost','XGBOOST_H'],\n",
    "    'MAPE': [0.151, 0.139, 0.095, 0.092, 0.085, 0.091,0.087],\n",
    "    'R-squared': [0.781, 0.749, 0.883, 0.878, 0.889, 0.874, 0.882]\n",
    "}\n",
    "\n",
    "compiled_results = pd.DataFrame(data)\n",
    "compiled_results.set_index('Model', inplace=True)\n",
    "print(compiled_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting metric columns\n",
    "metrics = compiled_results.columns  # Exclude 'Model'\n",
    "\n",
    "# Number of subplots\n",
    "num_plots = len(metrics)\n",
    "\n",
    "# Create a subplot with a 2x2 grid\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 8))\n",
    "\n",
    "# Flatten the 2x2 subplot grid for iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each metric and create a bar plot on each axis\n",
    "for i, metric in enumerate(metrics):\n",
    "    sns.barplot(x=compiled_results.index, y=compiled_results[metric], ax=axes[i])\n",
    "    axes[i].set_title(f'{metric} Comparison',fontsize=15)\n",
    "    axes[i].set_ylabel(metric,fontsize=15)\n",
    "    axes[i].set_xlabel('Model',fontsize=15)\n",
    "    axes[i].tick_params(axis='x', rotation=45, labelsize=12)\n",
    "    axes[i].tick_params(axis='y',labelsize=15)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaabfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
